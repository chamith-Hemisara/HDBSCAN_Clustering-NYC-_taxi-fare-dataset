{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10170,"databundleVersionId":61318,"sourceType":"competition"}],"dockerImageVersionId":5671,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport os # reading the input files we have access to\n\nprint(os.listdir('../input'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T11:35:38.281581Z","iopub.execute_input":"2023-12-10T11:35:38.281814Z","iopub.status.idle":"2023-12-10T11:35:38.307851Z","shell.execute_reply.started":"2023-12-10T11:35:38.281742Z","shell.execute_reply":"2023-12-10T11:35:38.307385Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"['sample_submission.csv', 'GCP-Coupons-Instructions.rtf', 'train.csv', 'test.csv']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the CSV file into a DataFrame\ndf = pd.read_csv('../input/train.csv')\n\n# Display the first few rows of the DataFrame to inspect the data\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:35:38.308680Z","iopub.execute_input":"2023-12-10T11:35:38.308828Z","iopub.status.idle":"2023-12-10T11:38:07.640101Z","shell.execute_reply.started":"2023-12-10T11:35:38.308809Z","shell.execute_reply":"2023-12-10T11:38:07.639408Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"                             key  fare_amount          pickup_datetime  \\\n0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n\n   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n0        -73.844311        40.721319         -73.841610         40.712278   \n1        -74.016048        40.711303         -73.979268         40.782004   \n2        -73.982738        40.761270         -73.991242         40.750562   \n3        -73.987130        40.733143         -73.991567         40.758092   \n4        -73.968095        40.768008         -73.956655         40.783762   \n\n   passenger_count  \n0                1  \n1                1  \n2                2  \n3                1  \n4                1  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming df is your DataFrame\nrow_count = df.shape[0]\n\nprint(\"Number of rows:\", row_count)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:07.641427Z","iopub.execute_input":"2023-12-10T11:38:07.641623Z","iopub.status.idle":"2023-12-10T11:38:07.645720Z","shell.execute_reply.started":"2023-12-10T11:38:07.641601Z","shell.execute_reply":"2023-12-10T11:38:07.645084Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of rows: 55423856\n","output_type":"stream"}]},{"cell_type":"code","source":"# Specify the size of the random sample you want\nsample_size = 150000  # Adjust this to the desired sample size\n\n# Get a random sample from the DataFrame\nrandom_sample = df.sample(n=sample_size)\n\n# Print the random sample\nprint(\"Random Sample:\")\nprint(random_sample)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:07.646547Z","iopub.execute_input":"2023-12-10T11:38:07.646710Z","iopub.status.idle":"2023-12-10T11:38:12.071429Z","shell.execute_reply.started":"2023-12-10T11:38:07.646689Z","shell.execute_reply":"2023-12-10T11:38:12.070753Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Random Sample:\n                                    key  fare_amount          pickup_datetime  \\\n35275929    2009-07-14 21:59:39.0000002         6.10  2009-07-14 21:59:39 UTC   \n23659976  2010-05-25 23:23:00.000000110         8.10  2010-05-25 23:23:00 UTC   \n19110511    2010-09-17 21:48:55.0000002         5.70  2010-09-17 21:48:55 UTC   \n21805989    2014-07-05 05:49:20.0000001        57.33  2014-07-05 05:49:20 UTC   \n14267926   2011-10-28 16:57:00.00000051         6.50  2011-10-28 16:57:00 UTC   \n...                                 ...          ...                      ...   \n31765792    2011-03-27 17:35:07.0000003        10.90  2011-03-27 17:35:07 UTC   \n9399816     2012-02-21 10:21:27.0000005         7.70  2012-02-21 10:21:27 UTC   \n53151792    2010-09-01 20:27:18.0000003         4.10  2010-09-01 20:27:18 UTC   \n40090907  2012-01-30 19:02:00.000000192         4.90  2012-01-30 19:02:00 UTC   \n52506326    2012-12-31 12:08:34.0000002        10.50  2012-12-31 12:08:34 UTC   \n\n          pickup_longitude  pickup_latitude  dropoff_longitude  \\\n35275929        -73.949474        40.785228         -73.932937   \n23659976        -73.981963        40.773023         -73.953395   \n19110511        -73.964852        40.791478         -73.964925   \n21805989        -73.968245        40.765059         -73.784073   \n14267926        -73.971405        40.755967         -73.984503   \n...                    ...              ...                ...   \n31765792        -74.013144        40.702282         -73.994299   \n9399816         -73.969933        40.763295         -73.987544   \n53151792        -73.952472        40.768631         -73.960212   \n40090907        -73.965107        40.761812         -73.965985   \n52506326        -73.975089        40.787914         -73.968094   \n\n          dropoff_latitude  passenger_count  \n35275929         40.795254                1  \n23659976         40.779457                1  \n19110511         40.791470                4  \n21805989         40.643561                1  \n14267926         40.757088                2  \n...                    ...              ...  \n31765792         40.722535                1  \n9399816          40.738328                2  \n53151792         40.760905                1  \n40090907         40.759452                5  \n52506326         40.762561                1  \n\n[150000 rows x 8 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df = random_sample","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:12.072874Z","iopub.execute_input":"2023-12-10T11:38:12.073108Z","iopub.status.idle":"2023-12-10T11:38:16.984124Z","shell.execute_reply.started":"2023-12-10T11:38:12.073077Z","shell.execute_reply":"2023-12-10T11:38:16.983409Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Display the number of missing values in each column\nmissing_values = df.isnull().sum()\nprint(\"Missing values per column:\")\nprint(missing_values)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:16.985168Z","iopub.execute_input":"2023-12-10T11:38:16.985392Z","iopub.status.idle":"2023-12-10T11:38:17.102024Z","shell.execute_reply.started":"2023-12-10T11:38:16.985347Z","shell.execute_reply":"2023-12-10T11:38:17.101362Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Missing values per column:\nkey                  0\nfare_amount          0\npickup_datetime      0\npickup_longitude     0\npickup_latitude      0\ndropoff_longitude    1\ndropoff_latitude     1\npassenger_count      0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Basically my objective is identify the popular areas and over  popular areas for taxi activities and how these vary over time in here I removing the unwanted columns for analysis.","metadata":{}},{"cell_type":"code","source":"# Remove unnecessary columns for analysis\ncolumns_to_keep = ['key', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']  # Add relevant column names\ndf = df[columns_to_keep]\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:17.102944Z","iopub.execute_input":"2023-12-10T11:38:17.103127Z","iopub.status.idle":"2023-12-10T11:38:17.134341Z","shell.execute_reply.started":"2023-12-10T11:38:17.103105Z","shell.execute_reply":"2023-12-10T11:38:17.133672Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                                    key          pickup_datetime  \\\n35275929    2009-07-14 21:59:39.0000002  2009-07-14 21:59:39 UTC   \n23659976  2010-05-25 23:23:00.000000110  2010-05-25 23:23:00 UTC   \n19110511    2010-09-17 21:48:55.0000002  2010-09-17 21:48:55 UTC   \n21805989    2014-07-05 05:49:20.0000001  2014-07-05 05:49:20 UTC   \n14267926   2011-10-28 16:57:00.00000051  2011-10-28 16:57:00 UTC   \n\n          pickup_longitude  pickup_latitude  dropoff_longitude  \\\n35275929        -73.949474        40.785228         -73.932937   \n23659976        -73.981963        40.773023         -73.953395   \n19110511        -73.964852        40.791478         -73.964925   \n21805989        -73.968245        40.765059         -73.784073   \n14267926        -73.971405        40.755967         -73.984503   \n\n          dropoff_latitude  \n35275929         40.795254  \n23659976         40.779457  \n19110511         40.791470  \n21805989         40.643561  \n14267926         40.757088  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Drop rows with missing values\ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:17.135399Z","iopub.execute_input":"2023-12-10T11:38:17.135622Z","iopub.status.idle":"2023-12-10T11:38:17.278926Z","shell.execute_reply.started":"2023-12-10T11:38:17.135596Z","shell.execute_reply":"2023-12-10T11:38:17.278099Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:17.279937Z","iopub.execute_input":"2023-12-10T11:38:17.280138Z","iopub.status.idle":"2023-12-10T11:38:32.853196Z","shell.execute_reply.started":"2023-12-10T11:38:17.280114Z","shell.execute_reply":"2023-12-10T11:38:32.852401Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Filter data for the year 2012\ndf_2012 = df[df['pickup_datetime'].dt.year == 2012]\n\n\n# Print the number of rows in the filtered DataFrame\nprint(\"Number of Rows for the Year 2012:\", len(df_2012))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:32.854785Z","iopub.execute_input":"2023-12-10T11:38:32.855146Z","iopub.status.idle":"2023-12-10T11:38:32.881666Z","shell.execute_reply.started":"2023-12-10T11:38:32.855117Z","shell.execute_reply":"2023-12-10T11:38:32.880907Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of Rows for the Year 2012: 24240\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define conditions for valid latitude and longitude values\nvalid_latitude_condition = ((df_2012['pickup_latitude'] != 0) & (df_2012['pickup_latitude'] >= 40.5) & (df_2012['pickup_latitude'] <= 40.9) &\n                            (df_2012['dropoff_latitude'] != 0) & (df_2012['dropoff_latitude'] >= 40.5) & (df_2012['dropoff_latitude'] <= 40.9))\nvalid_longitude_condition = ((df_2012['pickup_longitude'] != 0) & (df_2012['pickup_longitude'] >= -74.2) & (df_2012['pickup_longitude'] <= -73.6) &\n                             (df_2012['dropoff_longitude'] != 0) & (df_2012['dropoff_longitude'] >= -74.2) & (df_2012['dropoff_longitude'] <= -73.6))\n\n# Apply the conditions using loc to avoid the warning\ndf_cleaned = df_2012.loc[valid_latitude_condition & valid_longitude_condition]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:32.884296Z","iopub.execute_input":"2023-12-10T11:38:32.884521Z","iopub.status.idle":"2023-12-10T11:38:32.898217Z","shell.execute_reply.started":"2023-12-10T11:38:32.884496Z","shell.execute_reply":"2023-12-10T11:38:32.897546Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Assuming df is your DataFrame\nrow_count = df_cleaned.shape[0]\n\nprint(\"Number of rows:\", row_count)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:32.899054Z","iopub.execute_input":"2023-12-10T11:38:32.899231Z","iopub.status.idle":"2023-12-10T11:38:32.906867Z","shell.execute_reply.started":"2023-12-10T11:38:32.899208Z","shell.execute_reply":"2023-12-10T11:38:32.906213Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of rows: 23579\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the filtered DataFrame to a CSV file\ndf_cleaned.to_csv('Spatial_sample_150000.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T11:38:32.907720Z","iopub.execute_input":"2023-12-10T11:38:32.907906Z","iopub.status.idle":"2023-12-10T11:38:33.204414Z","shell.execute_reply.started":"2023-12-10T11:38:32.907884Z","shell.execute_reply":"2023-12-10T11:38:33.203733Z"},"trusted":true},"execution_count":13,"outputs":[]}]}